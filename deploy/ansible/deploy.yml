- hosts: local
  gather_facts: false

  vars:
    kube_ns: vehicle
    aws_region: "{{ lookup('env','AWS_REGION') }}"
    eks_cluster: "{{ lookup('env','EKS_CLUSTER') }}"

  tasks:
    - name: Configure kubeconfig for EKS
      ansible.builtin.command:
        cmd: aws eks update-kubeconfig --name {{ eks_cluster }} --region {{ aws_region }}

    - name: Ensure namespace exists
      kubernetes.core.k8s:
        state: present
        src: ../k8s/namespace.yaml
        template: true

    # (optional) clean up any old oracle secret if it exists
    - name: Remove deprecated Oracle secret if present
      kubernetes.core.k8s:
        state: absent
        kind: Secret
        name: oracle-secret
        namespace: "{{ kube_ns }}"
      ignore_errors: true

    - name: Apply Service
      kubernetes.core.k8s:
        state: present
        src: ../k8s/service.yaml
        template: true

    - name: Apply Deployment (uses {{ deploy_image }})
      kubernetes.core.k8s:
        state: present
        src: ../k8s/deployment.yaml
        template: true

    # If your deployment.yaml already uses {{ deploy_image }}, the step below isnâ€™t needed.
    # Keeping it as a safety override is fine; it will update the image explicitly.
    - name: Force image update to freshly built tag
      ansible.builtin.command:
        cmd: kubectl -n {{ kube_ns }} set image deploy/vehicle-app vehicle-app={{ deploy_image }}

    - name: Wait for rollout to complete
      ansible.builtin.command:
        cmd: kubectl -n {{ kube_ns }} rollout status deploy/vehicle-app --timeout=180s
